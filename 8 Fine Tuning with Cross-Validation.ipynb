{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcTph93DupVz4bAP6aaTSa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlyaZutler/Project-3-Berlin-Airbnb-Ratings/blob/main/8%20Fine%20Tuning%20with%20Cross-Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install openpyxl -q\n",
        "import openpyxl\n",
        "import pickle\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# for grid\n",
        "!pip install geopy -q\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import  make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# CatBoost\n",
        "!pip install catboost -q\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "# RandomForest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Linear Regression+l1 Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "# AdaBoost\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "# LightGBM\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_validate, KFold\n",
        "\n",
        "!pip -qq install category_encoders\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# Set display options\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_columns', 200)\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_colwidth', 1000)"
      ],
      "metadata": {
        "id": "1HOrwlqdfMkA"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "!wget https://github.com/IlyaZutler/Project-3-Berlin-Airbnb-Ratings/raw/main/apartments5.pkl -q\n",
        "\n",
        "with open('apartments5.pkl', 'rb') as f:\n",
        "    apartments_initial = pickle.load(f)"
      ],
      "metadata": {
        "id": "kp-M5l_fgHM-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CatBoost**"
      ],
      "metadata": {
        "id": "Vao8ovm6whui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apartments = apartments_initial.copy()"
      ],
      "metadata": {
        "id": "13QDt6ezRodU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apartments.drop(columns=['Host Since','First Review', 'Last Review','Reviews', 'Latitude_Bin', 'Longitude_Bin', 'Latitude_Bin2', 'Longitude_Bi2n','Listing ID', 'Price Log'], inplace=True)\n",
        "\n",
        "apartments['Is Superhost'] = apartments['Is Superhost'].replace({'t': 1, 'f': 0}).fillna(0).astype(int)\n",
        "apartments['Instant Bookable'] = apartments['Instant Bookable'].replace({'t': 1, 'f': 0}).fillna(0).astype(int)\n",
        "apartments['Is Exact Location'] = apartments['Is Exact Location'].replace({'t': 1, 'f': 0}).fillna(0).astype(int)\n",
        "\n",
        "# apartments['Host Response Time'] = apartments['Host Response Time'].replace(\n",
        "#     {'within an hour':0, 'within a few hours': 1, 'within a day': 2, 'a few days or more': 3 }).fillna(3).astype(int)\n",
        "\n",
        "# Convert non-numeric columns to categorical\n",
        "cat_features = apartments.select_dtypes(exclude=['number']).columns\n",
        "apartments[cat_features] = apartments[cat_features].astype('category')\n",
        "\n",
        "# Fill NaN values in categorical columns with 'missing'\n",
        "for col in cat_features:\n",
        "    if 'missing' not in apartments[col].cat.categories:\n",
        "        apartments[col] = apartments[col].cat.add_categories('missing')\n",
        "    apartments[col] = apartments[col].fillna('missing')\n",
        "\n",
        "num_features = apartments.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "apartments[cat_features] = apartments[cat_features].astype(str)"
      ],
      "metadata": {
        "id": "rVhMKE34gon-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = apartments.drop(columns=['Price'])\n",
        "y = apartments['Price']\n",
        "\n",
        "cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "num_features = X.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Define the model\n",
        "model = CatBoostRegressor(cat_features=cat_features, random_state=42, verbose=0)\n",
        "\n",
        "# Define cross-validation strategy\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store results\n",
        "train_mse_scores, test_mse_scores = [], []\n",
        "train_rmse_scores, test_rmse_scores = [], []\n",
        "train_r2_scores, test_r2_scores = [], []\n",
        "\n",
        "# Cross-validation loop\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on both training and test data\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and store the metrics\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    train_mse_scores.append(train_mse)\n",
        "    test_mse_scores.append(test_mse)\n",
        "\n",
        "    train_rmse_scores.append(train_rmse)\n",
        "    test_rmse_scores.append(test_rmse)\n",
        "\n",
        "    train_r2_scores.append(train_r2)\n",
        "    test_r2_scores.append(test_r2)\n",
        "\n",
        "# Output results\n",
        "print(\"Training MSE scores for each fold:\", train_mse_scores)\n",
        "print(\"Mean Training MSE:\", np.mean(train_mse_scores))\n",
        "print(\"Test MSE scores for each fold:\", test_mse_scores)\n",
        "print(\"Mean Test MSE:\", np.mean(test_mse_scores))\n",
        "\n",
        "print(\"\\nTraining RMSE scores for each fold:\", train_rmse_scores)\n",
        "print(\"Mean Training RMSE:\", np.mean(train_rmse_scores))\n",
        "print(\"Test RMSE scores for each fold:\", test_rmse_scores)\n",
        "print(\"Mean Test RMSE:\", np.mean(test_rmse_scores))\n",
        "\n",
        "print(\"\\nTraining R² scores for each fold:\", train_r2_scores)\n",
        "print(\"Mean Training R²:\", np.mean(train_r2_scores))\n",
        "print(\"Test R² scores for each fold:\", test_r2_scores)\n",
        "print(\"Mean Test R²:\", np.mean(test_r2_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wa8WbG0HQav",
        "outputId": "aa9f6c4a-28b1-4d70-9094-f073978e2981"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE scores for each fold: [491.39279332989184, 480.2388728077732, 478.97591852466076, 496.48328908184527, 486.7510437956254]\n",
            "Mean Training MSE: 486.76838350795924\n",
            "Test MSE scores for each fold: [660.4415224159895, 687.9739324004692, 713.9858506488222, 696.7097544975894, 618.5787381225125]\n",
            "Mean Test MSE: 675.5379596170766\n",
            "\n",
            "Training RMSE scores for each fold: [22.16738129166122, 21.91435312318785, 21.885518465977924, 22.281904969769645, 22.062435128417384]\n",
            "Mean Training RMSE: 22.062318595802804\n",
            "Test RMSE scores for each fold: [25.699056839035737, 26.229257183543517, 26.720513667383383, 26.395260076339262, 24.871243196159547]\n",
            "Mean Test RMSE: 25.983066192492295\n",
            "\n",
            "Training R² scores for each fold: [0.7139917843789786, 0.7182132595062057, 0.717158946787825, 0.7054971198105272, 0.7209388288418102]\n",
            "Mean Training R²: 0.7151599878650694\n",
            "Test R² scores for each fold: [0.6053629883792218, 0.6020569162566827, 0.5971143247448181, 0.6133812076144818, 0.6054259910057711]\n",
            "Mean Test R²: 0.604668285600195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l9ssUaEugJLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LightGBM**"
      ],
      "metadata": {
        "id": "lPf9oZ1EwrZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apartments = apartments_initial.copy()"
      ],
      "metadata": {
        "id": "0ycbeHTUq4Uv"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apartments.drop(columns=['Host Since','First Review', 'Last Review','Reviews', 'Latitude_Bin', 'Longitude_Bin', 'Latitude_Bin2', 'Longitude_Bi2n','Listing ID', 'Price Log'], inplace=True)\n",
        "\n",
        "apartments['Is Superhost'] = apartments['Is Superhost'].replace({'t': 1, 'f': 0}).fillna(0).astype(int)\n",
        "apartments['Instant Bookable'] = apartments['Instant Bookable'].replace({'t': 1, 'f': 0}).fillna(0).astype(int)\n",
        "apartments['Is Exact Location'] = apartments['Is Exact Location'].replace({'t': 1, 'f': 0}).fillna(0).astype(int)\n",
        "\n",
        "# apartments['Host Response Time'] = apartments['Host Response Time'].replace(\n",
        "#     {'within an hour':0, 'within a few hours': 1, 'within a day': 2, 'a few days or more': 3 }).fillna(3).astype(int)\n",
        "\n",
        "#Convert non-numeric columns to categorical\n",
        "cat_features = apartments.select_dtypes(exclude=['number']).columns\n",
        "apartments[cat_features] = apartments[cat_features].astype('category')\n",
        "\n",
        "# Fill NaN values in categorical columns with 'missing'\n",
        "for col in cat_features:\n",
        "    if 'missing' not in apartments[col].cat.categories:\n",
        "        apartments[col] = apartments[col].cat.add_categories('missing')\n",
        "    apartments[col] = apartments[col].fillna('missing')\n",
        "\n",
        "num_features = apartments.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "apartments[cat_features] = apartments[cat_features].astype(str)"
      ],
      "metadata": {
        "id": "5wgtRGyJq4Uv"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = apartments.drop(columns=['Price'])\n",
        "y = apartments['Price']\n",
        "\n",
        "cat_features = apartments.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "# Convert categorical columns to 'category' dtype\n",
        "for col in cat_features:\n",
        "    X[col] = X[col].astype('category')\n",
        "\n",
        "# Define the model\n",
        "model = lgb.LGBMRegressor(random_state=42)\n",
        "\n",
        "# Define cross-validation strategy\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store results\n",
        "train_mse_scores, test_mse_scores = [], []\n",
        "train_rmse_scores, test_rmse_scores = [], []\n",
        "train_r2_scores, test_r2_scores = [], []\n",
        "\n",
        "# Cross-validation loop\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    model.fit(X_train, y_train, categorical_feature=cat_features.tolist() )\n",
        "\n",
        "    # Predict on both training and test data\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate and store the metrics\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    train_mse_scores.append(train_mse)\n",
        "    test_mse_scores.append(test_mse)\n",
        "\n",
        "    train_rmse_scores.append(train_rmse)\n",
        "    test_rmse_scores.append(test_rmse)\n",
        "\n",
        "    train_r2_scores.append(train_r2)\n",
        "    test_r2_scores.append(test_r2)\n",
        "\n",
        "# Output results\n",
        "print(\"Training MSE scores for each fold:\", train_mse_scores)\n",
        "print(\"Mean Training MSE:\", np.mean(train_mse_scores))\n",
        "print(\"Test MSE scores for each fold:\", test_mse_scores)\n",
        "print(\"Mean Test MSE:\", np.mean(test_mse_scores))\n",
        "\n",
        "print(\"\\nTraining RMSE scores for each fold:\", train_rmse_scores)\n",
        "print(\"Mean Training RMSE:\", np.mean(train_rmse_scores))\n",
        "print(\"Test RMSE scores for each fold:\", test_rmse_scores)\n",
        "print(\"Mean Test RMSE:\", np.mean(test_rmse_scores))\n",
        "\n",
        "print(\"\\nTraining R² scores for each fold:\", train_r2_scores)\n",
        "print(\"Mean Training R²:\", np.mean(train_r2_scores))\n",
        "print(\"Test R² scores for each fold:\", test_r2_scores)\n",
        "print(\"Mean Test R²:\", np.mean(test_r2_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gdB8Aj7kwnwS",
        "outputId": "a1e3130a-0bc6-40b3-e180-df73af9f74dc"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004248 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5313\n",
            "[LightGBM] [Info] Number of data points in the train set: 17067, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 59.649616\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004699 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5309\n",
            "[LightGBM] [Info] Number of data points in the train set: 17067, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 59.531201\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004192 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5313\n",
            "[LightGBM] [Info] Number of data points in the train set: 17067, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 59.566649\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004492 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5314\n",
            "[LightGBM] [Info] Number of data points in the train set: 17067, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 59.436281\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006496 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 5326\n",
            "[LightGBM] [Info] Number of data points in the train set: 17068, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 59.861612\n",
            "Training MSE scores for each fold: [356.21889001658985, 356.93417396935024, 350.7450816670232, 359.48402727048864, 359.02675716385835]\n",
            "Mean Training MSE: 356.481786017462\n",
            "Test MSE scores for each fold: [741.9067882157362, 726.5002470383824, 754.5393185613275, 748.6652895420998, 691.3121696260047]\n",
            "Mean Test MSE: 732.5847625967101\n",
            "\n",
            "Training RMSE scores for each fold: [18.873761946591088, 18.892701605894015, 18.728189492500956, 18.960064010189644, 18.948001402888337]\n",
            "Mean Training RMSE: 18.880543691612807\n",
            "Test RMSE scores for each fold: [27.237965933889708, 26.953668526536095, 27.46887909182549, 27.361748656511335, 26.29281593184733]\n",
            "Mean Test RMSE: 27.063015628121992\n",
            "\n",
            "Training R² scores for each fold: [0.7926678402958414, 0.7905639814919203, 0.7928808015792062, 0.786762044682198, 0.794164946108794]\n",
            "Mean Training R²: 0.7914079228315919\n",
            "Test R² scores for each fold: [0.5566846301068678, 0.5797722340467292, 0.5742309422673897, 0.5845499962140657, 0.5590313772119873]\n",
            "Mean Test R²: 0.570853835969408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBRegressor**"
      ],
      "metadata": {
        "id": "KgQXa_iTLTum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apartments = apartments_initial.copy()"
      ],
      "metadata": {
        "id": "f-o6ImOeLcuL"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apartments.drop(columns=['Host Since','First Review', 'Last Review','Reviews', 'Latitude_Bin', 'Longitude_Bin', 'Latitude_Bin2', 'Longitude_Bi2n','Listing ID', 'Price Log'], inplace=True)\n",
        "\n",
        "apartments['Is Superhost'] = apartments['Is Superhost'].replace({'t': 1, 'f': 0}).fillna(0).astype(int)\n",
        "apartments['Instant Bookable'] = apartments['Instant Bookable'].replace({'t': 1, 'f': 0}).fillna(0).astype(int)\n",
        "apartments['Is Exact Location'] = apartments['Is Exact Location'].replace({'t': 1, 'f': 0}).fillna(0).astype(int)\n",
        "\n",
        "# apartments['Host Response Time'] = apartments['Host Response Time'].replace(\n",
        "#     {'within an hour':0, 'within a few hours': 1, 'within a day': 2, 'a few days or more': 3 }).fillna(3).astype(int)\n",
        "\n",
        "# # Convert non-numeric columns to categorical\n",
        "# cat_features = apartments.select_dtypes(exclude=['number']).columns\n",
        "# apartments[cat_features] = apartments[cat_features].astype('category')\n",
        "\n",
        "# # Fill NaN values in categorical columns with 'missing'\n",
        "# for col in cat_features:\n",
        "#     if 'missing' not in apartments[col].cat.categories:\n",
        "#         apartments[col] = apartments[col].cat.add_categories('missing')\n",
        "#     apartments[col] = apartments[col].fillna('missing')\n",
        "\n",
        "# num_features = apartments.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# apartments[cat_features] = apartments[cat_features].astype(str)"
      ],
      "metadata": {
        "id": "zW-JMjGsLcuM"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = apartments.drop(columns=['Price'])\n",
        "y = apartments['Price']\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "num_features = X.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Preprocessor for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='mean')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), num_features),\n",
        "\n",
        "        ('cat', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "            ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
        "        ]), cat_features)\n",
        "    ])\n",
        "\n",
        "# Define the model\n",
        "model = XGBRegressor(colsample_bytree = 0.32,\n",
        "                     n_estimators = 80, #150, 200\n",
        "                     gamma = 0.1, # 0.2 хуже\n",
        "                     subsample = 1, #пробовал 0.7\n",
        "                     learning_rate = 0.2, # 0.4\n",
        "                     reg_alpha = 0, #Л1 регуляризация\n",
        "                     min_child_weight = 1,\n",
        "                     max_depth = 6,\n",
        "                     random_state=42)\n",
        "\n",
        "# Create a pipeline that combines preprocessing and the model\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "# Define cross-validation strategy\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store results\n",
        "train_mse_scores, test_mse_scores = [], []\n",
        "train_rmse_scores, test_rmse_scores = [], []\n",
        "train_r2_scores, test_r2_scores = [], []\n",
        "\n",
        "# Cross-validation loop\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the pipeline on the training data\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on both training and test data\n",
        "    y_train_pred = pipeline.predict(X_train)\n",
        "    y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Calculate and store the metrics\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    train_mse_scores.append(train_mse)\n",
        "    test_mse_scores.append(test_mse)\n",
        "\n",
        "    train_rmse_scores.append(train_rmse)\n",
        "    test_rmse_scores.append(test_rmse)\n",
        "\n",
        "    train_r2_scores.append(train_r2)\n",
        "    test_r2_scores.append(test_r2)\n",
        "\n",
        "# Output results\n",
        "print(\"Training MSE scores for each fold:\", train_mse_scores)\n",
        "print(\"Mean Training MSE:\", np.mean(train_mse_scores))\n",
        "print(\"Test MSE scores for each fold:\", test_mse_scores)\n",
        "print(\"Mean Test MSE:\", np.mean(test_mse_scores))\n",
        "\n",
        "print(\"\\nTraining RMSE scores for each fold:\", train_rmse_scores)\n",
        "print(\"Mean Training RMSE:\", np.mean(train_rmse_scores))\n",
        "print(\"Test RMSE scores for each fold:\", test_rmse_scores)\n",
        "print(\"Mean Test RMSE:\", np.mean(test_rmse_scores))\n",
        "\n",
        "print(\"\\nTraining R² scores for each fold:\", train_r2_scores)\n",
        "print(\"Mean Training R²:\", np.mean(train_r2_scores))\n",
        "print(\"Test R² scores for each fold:\", test_r2_scores)\n",
        "print(\"Mean Test R²:\", np.mean(test_r2_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGOgWXMUFDRH",
        "outputId": "4a1df140-58bd-4358-b2b2-a651e0e32291"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE scores for each fold: [452.1233974610468, 453.11668404146803, 444.2306604225464, 445.7405575621153, 454.06377890356816]\n",
            "Mean Training MSE: 449.855015678149\n",
            "Test MSE scores for each fold: [707.0434247866888, 700.9645459761849, 732.944632446368, 716.397652902389, 638.5291374477396]\n",
            "Mean Test MSE: 699.175878711874\n",
            "\n",
            "Training RMSE scores for each fold: [21.263193491595914, 21.286537624552004, 21.076780124643005, 21.11256871065469, 21.308772346232622]\n",
            "Mean Training RMSE: 21.209570459535644\n",
            "Test RMSE scores for each fold: [26.590288166672597, 26.475735041282327, 27.072950198424405, 26.765605782466217, 25.269134085831663]\n",
            "Mean Test RMSE: 26.434742654935445\n",
            "\n",
            "Training R² scores for each fold: [0.7368479800607572, 0.7341275754857322, 0.7376764404981584, 0.7355965831960474, 0.7396788943003354]\n",
            "Mean Training R²: 0.7367854947082062\n",
            "Test R² scores for each fold: [0.5775167145408663, 0.5945427873303137, 0.5864163233774538, 0.6024559816409178, 0.5927001914306302]\n",
            "Mean Test R²: 0.5907263996640364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gi-2ZZMrHQq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5R9o_zh50Y_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dw7xM-Uq0Y82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**no train metrix**"
      ],
      "metadata": {
        "id": "BAQXPwoaR4eL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = pd.DataFrame(data.data, columns=data.feature_names), pd.Series(data.target, name='target')\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "num_features = X.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Preprocessor for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Pipeline for numerical features: imputing missing values with mean and standard scaling\n",
        "        ('num', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='mean')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), num_features),\n",
        "\n",
        "        # Pipeline for categorical features: imputing missing values with 'missing' and One-Hot Encoding\n",
        "        ('cat', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "            ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
        "        ]), cat_features)\n",
        "    ])\n",
        "\n",
        "# Define the model\n",
        "model = XGBRegressor(random_state=42)\n",
        "\n",
        "# Create a pipeline that combines preprocessing and model\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "# Define cross-validation strategy\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Scoring metrics\n",
        "scoring = {\n",
        "    'mse': make_scorer(mean_squared_error),  # MSE\n",
        "    'rmse': make_scorer(mean_squared_error, squared=False),  # RMSE\n",
        "    'r2': make_scorer(r2_score)  # R^2\n",
        "}\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results = cross_validate(pipeline, X, y, cv=kf, scoring=scoring)\n",
        "\n",
        "# Extract the scores\n",
        "mse_scores = cv_results['test_mse']\n",
        "rmse_scores = cv_results['test_rmse']\n",
        "r2_scores = cv_results['test_r2']\n",
        "\n",
        "# Output results\n",
        "print(\"Cross-validated MSE scores for each fold:\", mse_scores)\n",
        "print(\"Mean cross-validated MSE:\", np.mean(mse_scores))\n",
        "print(\"\\nCross-validated RMSE scores for each fold:\", rmse_scores)\n",
        "print(\"Mean cross-validated RMSE:\", np.mean(rmse_scores))\n",
        "print(\"\\nCross-validated R² scores for each fold:\", r2_scores)\n",
        "print(\"Mean cross-validated R²:\", np.mean(r2_scores))\n"
      ],
      "metadata": {
        "id": "Xd_OLyqM0Y6C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}